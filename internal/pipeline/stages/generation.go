package stages

import (
	"context"
	"fmt"

	// "runtime"
	"time"

	"github.com/nashabanov/ueba-event-generator/internal/domain/event"
	"github.com/nashabanov/ueba-event-generator/internal/metrics"
	"github.com/nashabanov/ueba-event-generator/internal/workers"
)

// EventGenerationJob - –∑–∞–¥–∞—á–∞ –¥–ª—è Worker Pool
type EventGenerationJob struct {
	stage *EventGenerationStage
	out   chan<- *SerializedData
}

// Execute —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å workers.Job
func (job *EventGenerationJob) Execute() error {
	startTime := time.Now()

	err := job.stage.generateAndSendEvent(context.Background(), job.out)

	processingTime := time.Since(startTime)
	metrics.GetGlobalMetrics().RecordProcessingTime(processingTime)

	return err
}

// EventGenerationStage —Ä–µ–∞–ª–∏–∑—É–µ—Ç GenerationStage
type EventGenerationStage struct {
	name            string
	eventTypes      []event.EventType
	eventsPerSecond int

	// –ù–û–í–´–ï –ü–û–õ–Ø –¥–ª—è Worker Pool
	workerPool *workers.WorkerPool
	ticker     *time.Ticker
}

// NewEventGenerationStage —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Å—Ç–∞–¥–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
func NewEventGenerationStage(name string, eventsPerSecond int) *EventGenerationStage {
	queueSize := eventsPerSecond * 2
	if queueSize <= 1000 {
		queueSize = 1000
	}

	// workerCount := runtime.NumCPU() * 3
	workerPool := workers.NewWorkerPool(0, queueSize)
	workerPool.SetPoolType("generation")

	// fmt.Printf("üîß Creating EventGenerationStage: EPS=%d, QueueSize=%d, Workers=%d\n",
	// 	eventsPerSecond, queueSize, workerCount) //

	return &EventGenerationStage{
		name:            name,
		eventsPerSecond: eventsPerSecond,
		eventTypes:      []event.EventType{event.EventTypeNetflow}, // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
		workerPool:      workers.NewWorkerPool(0, queueSize),
	}
}

func (g *EventGenerationStage) Name() string {
	return g.name
}

func (g *EventGenerationStage) Run(ctx context.Context, out chan<- *SerializedData) error {
	measuredTickerEPS := 1160 // –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –ø—Ä–µ–¥–µ–ª —Å–∏—Å—Ç–µ–º—ã
	safetyMargin := 0.95      // 5% –∑–∞–ø–∞—Å –Ω–∞ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å

	effectiveTickerEPS := int(float64(measuredTickerEPS) * safetyMargin) // 1102 EPS
	batchSize := (g.eventsPerSecond + effectiveTickerEPS - 1) / effectiveTickerEPS

	if g.eventsPerSecond >= 50000 && batchSize > 100 {
		// –î–ª—è –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥
		effectiveTickerEPS = 1000
		batchSize = g.eventsPerSecond / effectiveTickerEPS
	}

	interval := time.Second / time.Duration(effectiveTickerEPS)
	expectedEPS := effectiveTickerEPS * batchSize
	accuracy := float64(expectedEPS) / float64(g.eventsPerSecond) * 100

	// fmt.Printf("üöÄ Calibrated batch generation:\n")
	// fmt.Printf("   Target EPS: %d\n", g.eventsPerSecond)
	// fmt.Printf("   Measured system limit: %d EPS\n", measuredTickerEPS)
	// fmt.Printf("   Effective ticker EPS: %d (with %.0f%% safety margin)\n",
	// 	effectiveTickerEPS, (1-safetyMargin)*100)
	// fmt.Printf("   Batch size: %d events per tick\n", batchSize)
	// fmt.Printf("   Expected EPS: %d\n", expectedEPS)
	// fmt.Printf("   Expected accuracy: %.1f%%\n", accuracy)

	// –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∑–∫–æ–π
	if accuracy < 95.0 {
		fmt.Printf("‚ö†Ô∏è  Low accuracy warning: consider increasing batch size\n")
	} else if accuracy > 105.0 {
		fmt.Printf("‚ö†Ô∏è  Over-target warning: batch size may be too large\n")
	}

	g.ticker = time.NewTicker(interval)
	defer g.ticker.Stop()

	g.workerPool.Start(ctx)
	defer g.workerPool.Stop()

	globalMetrics := metrics.GetGlobalMetrics()

	// –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
	tickCount := 0
	totalJobsSubmitted := 0
	totalJobsRejected := 0
	startTime := time.Now()

	for {
		select {
		case <-g.ticker.C:
			tickCount++

			// –ì–ï–ù–ï–†–ò–†–£–ï–ú BATCH –°–û–ë–´–¢–ò–ô –∑–∞ –æ–¥–∏–Ω —Ç–∏–∫
			batchSubmitted := 0
			batchRejected := 0

			for i := 0; i < batchSize; i++ {
				job := &EventGenerationJob{
					stage: g,
					out:   out,
				}

				if g.workerPool.Submit(job) {
					batchSubmitted++
					totalJobsSubmitted++
				} else {
					batchRejected++
					totalJobsRejected++
					globalMetrics.IncrementDropped()

					// –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø–æ–ª–Ω–∞—è, –ø—Ä–µ—Ä—ã–≤–∞–µ–º batch
					if batchRejected > batchSize/2 {
						break
					}
				}
			}

			// –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–∞–∂–¥—ã–µ 1000 —Ç–∏–∫–æ–≤ (–∏–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã)
			if tickCount%1000 == 0 || batchRejected > 0 {
				elapsed := time.Since(startTime).Seconds()
				actualTickRate := float64(tickCount) / elapsed
				expectedEvents := tickCount * batchSize
				actualEvents := totalJobsSubmitted

				fmt.Printf("üîç Tick %d: rate=%.1f/sec, batch=%d/%d, total_jobs=%d/%d (%.1f%% efficiency)\n",
					tickCount, actualTickRate, batchSubmitted, batchSize,
					actualEvents, expectedEvents, float64(actualEvents)/float64(expectedEvents)*100)
			}

		case <-ctx.Done():
			// ‚úÖ –§–ò–ù–ê–õ–¨–ù–ê–Ø —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
			// elapsed := time.Since(startTime).Seconds()
			// actualTickRate := float64(tickCount) / elapsed
			// expectedEvents := tickCount * batchSize
			// actualEPS := float64(totalJobsSubmitted) / elapsed

			// fmt.Printf("üõë Batch generation stopped:\n")
			// fmt.Printf("   Runtime: %.1fs\n", elapsed)
			// fmt.Printf("   Ticks: %d (rate: %.1f/sec)\n", tickCount, actualTickRate)
			// fmt.Printf("   Jobs: submitted=%d, rejected=%d\n", totalJobsSubmitted, totalJobsRejected)
			// fmt.Printf("   Expected events: %d, Actual EPS: %.1f\n", expectedEvents, actualEPS)
			// fmt.Printf("   Efficiency: %.1f%%\n", float64(totalJobsSubmitted)/float64(expectedEvents)*100)

			return ctx.Err()
		}
	}
}

// generateAndSendEvent –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –ø–∞–∫–µ—Ç–∞ event
func (g *EventGenerationStage) generateAndSendEvent(ctx context.Context, out chan<- *SerializedData) error {
	eventType := g.eventTypes[0]

	var evt event.Event
	switch eventType {
	case event.EventTypeNetflow:
		evt = event.NewNetflowEvent()
	case event.EventTypeSyslog:
		evt = event.NewSyslogEvent()
	default:
		return fmt.Errorf("unsupported event type: %v", eventType)
	}

	jsonData, err := evt.ToJSON()
	if err != nil {
		return fmt.Errorf("failed to serialize event: %w", err)
	}

	serializedData := NewSerializedData(jsonData, evt.Type(), evt.GetID())

	globalMetrics := metrics.GetGlobalMetrics()

	select {
	case out <- serializedData:
		globalMetrics.IncrementGenerated()
		return nil
	case <-ctx.Done():
		return ctx.Err()
	}
}

// –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
func (g *EventGenerationStage) SetEventRate(eventsPerSecond int) error {
	if eventsPerSecond <= 0 {
		return fmt.Errorf("events per second must be positive, got: %d", eventsPerSecond)
	}
	g.eventsPerSecond = eventsPerSecond
	return nil
}

func (g *EventGenerationStage) SetEventTypes(types []event.EventType) error {
	if len(types) == 0 {
		return fmt.Errorf("event types cannot be empty")
	}
	g.eventTypes = types
	return nil
}

func (g *EventGenerationStage) GetGeneratedCount() uint64 {
	generated, _, _, _ := metrics.GetGlobalMetrics().GetStats()
	return generated
}

func (g *EventGenerationStage) GetFailedCount() uint64 {
	_, _, failed, _ := metrics.GetGlobalMetrics().GetStats()
	return failed
}
